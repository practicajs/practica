"use strict";(self.webpackChunkpractica_docs=self.webpackChunkpractica_docs||[]).push([[9768],{3905:(e,t,o)=>{o.d(t,{Zo:()=>c,kt:()=>u});var n=o(7294);function a(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function i(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,n)}return o}function r(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?i(Object(o),!0).forEach((function(t){a(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):i(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function s(e,t){if(null==e)return{};var o,n,a=function(e,t){if(null==e)return{};var o,n,a={},i=Object.keys(e);for(n=0;n<i.length;n++)o=i[n],t.indexOf(o)>=0||(a[o]=e[o]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)o=i[n],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(a[o]=e[o])}return a}var l=n.createContext({}),h=function(e){var t=n.useContext(l),o=t;return e&&(o="function"==typeof e?e(t):r(r({},t),e)),o},c=function(e){var t=h(e.components);return n.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var o=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=h(o),u=a,m=d["".concat(l,".").concat(u)]||d[u]||p[u]||i;return o?n.createElement(m,r(r({ref:t},c),{},{components:o})):n.createElement(m,r({ref:t},c))}));function u(e,t){var o=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=o.length,r=new Array(i);r[0]=d;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,r[1]=s;for(var h=2;h<i;h++)r[h]=o[h];return n.createElement.apply(null,r)}return n.createElement.apply(null,o)}d.displayName="MDXCreateElement"},5849:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>l,contentTitle:()=>r,default:()=>p,frontMatter:()=>i,metadata:()=>s,toc:()=>h});var n=o(7462),a=(o(7294),o(3905));const i={slug:"monorepo-backend",date:"2022-11-07T11:00",title:"Which Monorepo is right for a Node.js BACKEND\xa0now?",authors:["goldbergyoni","michaelsalomon"],tags:["monorepo","decisions"]},r="Which Monorepo is right for a Node.js BACKEND\xa0now?",s={permalink:"/blog/monorepo-backend",editUrl:"https://github.com/practicajs/practica/tree/main/docs/blog/which-monorepo/index.md",source:"@site/blog/which-monorepo/index.md",title:"Which Monorepo is right for a Node.js BACKEND\xa0now?",description:"As a Node.js starter, choosing the right libraries and frameworks for our users is the bread and butter of our work in Practica.js. In this post, we'd like to share our considerations in choosing our monorepo tooling",date:"2022-11-07T11:00:00.000Z",formattedDate:"November 7, 2022",tags:[{label:"monorepo",permalink:"/blog/tags/monorepo"},{label:"decisions",permalink:"/blog/tags/decisions"}],readingTime:16.925,hasTruncateMarker:!0,authors:[{name:"Yoni Goldberg",title:"Practica.js core maintainer",url:"https://github.com/goldbergyoni",imageURL:"https://github.com/goldbergyoni.png",key:"goldbergyoni"},{name:"Michael Salomon",title:"Practica.js core maintainer",url:"https://github.com/mikicho",imageURL:"https://avatars.githubusercontent.com/u/11459632?v=4",key:"michaelsalomon"}],frontMatter:{slug:"monorepo-backend",date:"2022-11-07T11:00",title:"Which Monorepo is right for a Node.js BACKEND\xa0now?",authors:["goldbergyoni","michaelsalomon"],tags:["monorepo","decisions"]},prevItem:{title:"Is Prisma better than your 'traditional' ORM?",permalink:"/blog/is-prisma-better-than-your-traditional-orm"},nextItem:{title:"Popular Node.js patterns and tools to re-consider",permalink:"/blog/popular-nodejs-pattern-and-tools-to-reconsider"}},l={authorsImageUrls:[void 0,void 0]},h=[{value:"What are we looking\xa0at",id:"what-are-we-lookingat",level:2}],c={toc:h};function p(e){let{components:t,...i}=e;return(0,a.kt)("wrapper",(0,n.Z)({},c,i,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"As a Node.js starter, choosing the right libraries and frameworks for our users is the bread and butter of our work in ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/practicajs/practica"},"Practica.js"),". In this post, we'd like to share our considerations in choosing our monorepo tooling"),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Monorepos",src:o(1377).Z,width:"1400",height:"796"})),(0,a.kt)("h2",{id:"what-are-we-lookingat"},"What are we looking\xa0at"),(0,a.kt)("p",null,"The Monorepo market is hot like fire. Weirdly, now when the demand for Monoreps is exploding, one of the leading libraries \u2014  ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/lerna/lerna/issues/2703"},"Lerna- has just retired."),"  When looking closely, it might not be just a coincidence \u2014 With so many disruptive and shiny features brought on by new vendors, Lerna failed to keep up with the pace and stay relevant. This bloom of new tooling gets many confused \u2014 What is the right choice for my next project? What should I look at when choosing a Monorepo tool? This post is all about curating this information overload, covering the new tooling, emphasizing what is important, and finally share some recommendations. If you are here for tools and features, you\u2019re in the right place, although you might find yourself on a soul-searching journey to what is your desired development workflow."),(0,a.kt)("p",null,"This post is concerned with backend-only and Node.js. It also scoped to  ",(0,a.kt)("em",{parentName:"p"},"typical"),"  business solutions. If you\u2019re Google/FB developer who is faced with 8,000 packages \u2014 sorry, you need special gear. Consequently, monster Monorepo tooling like  ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/thundergolfer/example-bazel-monorepo"},"Bazel"),"  is left-out. We will cover here some of the most popular Monorepo tools including Turborepo, Nx, PNPM, Yarn/npm workspace, and Lerna (although it\u2019s not actually maintained anymore \u2014 it\u2019s a good baseline for comparison)."),(0,a.kt)("p",null,"Let\u2019s start? When human beings use the term Monorepo, they typically refer to one or more of the following  ",(0,a.kt)("em",{parentName:"p"},"4 layers below.")," Each one of them can bring value to your project, each has different consequences, tooling, and features:"),(0,a.kt)("h1",{id:"layer-1-plain-old-folders-to-stay-on-top-of-your-code"},"Layer 1: Plain old folders to stay on top of your code"),(0,a.kt)("p",null,"With zero tooling and only by having all the Microservice and libraries together in the same root folder, a developer gets great management perks and tons of value: Navigation, search across components, deleting a library instantly, debugging,  ",(0,a.kt)("em",{parentName:"p"},"quickly"),"  adding new components. Consider the alternative with multi-repo approach \u2014 adding a new component for modularity demands opening and configuring a new  GitHub  repository. Not just a hassle but also greater chances of developers choosing the short path and including the new code in some semi-relevant existing package. In plain words, zero-tooling Monorepos can increase modularity."),(0,a.kt)("p",null,"This layer is often overlooked. If your codebase is not huge and the components are highly decoupled (more on this later)\u2014 it might be all you need. We\u2019ve seen a handful of successful Monorepo solutions without any special tooling."),(0,a.kt)("p",null,"With that said, some of the newer tools augment this experience with interesting features:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Both  ",(0,a.kt)("a",{parentName:"li",href:"https://turborepo.org/"},"Turborepo"),"  and  ",(0,a.kt)("a",{parentName:"li",href:"https://nx.dev/structure/dependency-graph"},"Nx"),"  and also  ",(0,a.kt)("a",{parentName:"li",href:"https://www.npmjs.com/package/lerna-dependency-graph"},"Lerna"),"  provide a visual representation of the packages\u2019 dependencies"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://nx.dev/structure/monorepo-tags"},"Nx allows \u2018visibility rules\u2019"),"  which is about enforcing who can use what. Consider, a \u2018checkout\u2019 library that should be approached only by the \u2018order Microservice\u2019 \u2014 deviating from this will result in failure during development (not runtime enforcement)")),(0,a.kt)("p",null,(0,a.kt)("img",{parentName:"p",src:"https://miro.medium.com/max/1400/0*pHZKRlGT6iOKCmzg.jpg",alt:null})),(0,a.kt)("p",null,"Nx dependencies graph"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://nx.dev/generators/workspace-generators"},"Nx workspace generator"),"  allows scaffolding out components. Whenever a team member needs to craft a new controller/library/class/Microservice, she just invokes a CLI command which products code based on a community or organization template. This enforces consistency and best practices sharing")),(0,a.kt)("h1",{id:"layer-2-tasks-and-pipeline-to-build-your-code-efficiently"},"Layer 2: Tasks and pipeline to build your code efficiently"),(0,a.kt)("p",null,"Even in a world of autonomous components, there are management tasks that must be applied in a batch like applying a security patch via npm update, running the tests of  ",(0,a.kt)("em",{parentName:"p"},"multiple"),"  components that were affected by a change, publish 3 related libraries to name a few examples. All Monorepo tools support this basic functionality of invoking some command over a group of packages. For example, Lerna, Nx, and Turborepo do."),(0,a.kt)("p",null,(0,a.kt)("img",{parentName:"p",src:"https://miro.medium.com/max/1400/1*wu7xtN97-Ihz4uCSDwd0mA.png",alt:null})),(0,a.kt)("p",null,"Apply some commands over multiple packages"),(0,a.kt)("p",null,"In some projects, invoking a cascading command is all you need. Mostly if each package has an autonomous life cycle and the build process spans a single package (more on this later). In some other types of projects where the workflow demands testing/running and publishing/deploying many packages together \u2014 this will end in a terribly slow experience. Consider a solution with hundred of packages that are transpiled and bundled \u2014 one might wait minutes for a wide test to run. While it\u2019s not always a great practice to rely on wide/E2E tests, it\u2019s quite common in the wild. This is exactly where the new wave of Monorepo tooling shines \u2014  ",(0,a.kt)("em",{parentName:"p"},"deeply"),"  optimizing the build process. I should say this out loud: These tools bring beautiful and innovative build optimizations:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Parallelization \u2014")," If two commands or packages are orthogonal to each other, the commands will run in two different threads or processes. Typically your quality control involves testing, lining, license checking, CVE checking \u2014 why not parallelize?"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Smart execution plan \u2014"),"Beyond parallelization, the optimized tasks execution order is determined based on many factors. Consider a build that includes A, B, C where A, C depend on B \u2014 naively, a build system would wait for B to build and only then run A & C. This can be optimized if we run A & C\u2019s  ",(0,a.kt)("em",{parentName:"li"},"isolated"),"  unit tests  ",(0,a.kt)("em",{parentName:"li"},"while")," building B and not afterward. By running task in parallel as early as possible, the overall execution time is improved \u2014 this has a remarkable impact mostly when hosting a high number of components. See below a visualization example of a pipeline improvement")),(0,a.kt)("p",null,(0,a.kt)("img",{parentName:"p",src:"https://miro.medium.com/max/1400/0*C6cxCblQU8ckTIQk.png",alt:null})),(0,a.kt)("p",null,"A modern tool advantage over old Lerna. Taken from Turborepo website"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Detect who is affected by a change \u2014"),"  Even on a system with high coupling between packages, it\u2019s usually not necessary to run  ",(0,a.kt)("em",{parentName:"li"},"all")," packages rather than only those who are affected by a change. What exactly is \u2018affected\u2019? Packages/Microservices that depend upon another package that has changed. Some of the toolings can ignore minor changes that are unlikely to break others. This is not a great performance booster but also an amazing testing feature \u2014developers can get quick feedback on whether any of their clients were broken. Both Nx and Turborepo support this feature. Lerna can tell only which of the Monorepo package has changed"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Sub-systems (i.e., projects) \u2014")," Similarly to \u2018affected\u2019 above, modern tooling can realize portions of the graph that are inter-connected (a project or application) while others are not reachable by the component in context (another project) so they know to involve only packages of the relevant group"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Caching \u2014")," This is a serious speed booster: Nx and Turborepo cache the result/output of tasks and avoid running them again on consequent builds if unnecessary. For example, consider long-running tests of a Microservice, when commanding to re-build this Microservice, the tooling might realize that nothing has changed and the test will get skipped. This is achieved by generating a hashmap of all the dependent resources \u2014 if any of these resources haven\u2019t change, then the hashmap will be the same and the task will get skipped. They even cache the stdout of the command, so when you run a cached version it acts like the real thing \u2014 consider running 200 tests, seeing all the log statements of the tests, getting results over the terminal in 200 ms, everything acts like \u2018real testing while in fact, the tests did not run at all rather the cache!"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},"Remote caching \u2014")," Similarly to caching, only by placing the task\u2019s hashmaps and result on a global server so further executions on other team member\u2019s computers will also skip unnecessary tasks. In huge Monorepo projects that rely on E2E tests and must build all packages for development, this can save a great deal of time")),(0,a.kt)("h1",{id:"layer-3-hoist-your-dependencies-to-boost-npm-installation"},"Layer 3: Hoist your dependencies to boost npm installation"),(0,a.kt)("p",null,"The speed optimizations that were described above won\u2019t be of help if the bottleneck is the big bull of mud that is called \u2018npm install\u2019 (not to criticize, it\u2019s just hard by nature). Take a typical scenario as an example, given dozens of components that should be built, they could easily trigger the installation of thousands of sub-dependencies. Although they use quite similar dependencies (e.g., same logger, same ORM), if the dependency version is not equal then npm will duplicate (",(0,a.kt)("a",{parentName:"p",href:"https://rushjs.io/pages/advanced/npm_doppelgangers/"},"the NPM doppelgangers problem"),") the installation of those packages which might result in a long process."),(0,a.kt)("p",null,"This is where the workspace line of tools (e.g., Yarn workspace, npm workspaces, PNPM) kicks in and introduces some optimization \u2014 Instead of installing dependencies inside each component \u2018NODE_MODULES\u2019 folder, it will create one centralized folder and link all the dependencies over there. This can show a tremendous boost in install time for huge projects. On the other hand, if you always focus on one component at a time, installing the packages of a single Microservice/library should not be a concern."),(0,a.kt)("p",null,"Both Nx and Turborepo can rely on the package manager/workspace to provide this layer of optimizations. In other words, Nx and Turborepo are the layer above the package manager who take care of optimized dependencies installation."),(0,a.kt)("p",null,(0,a.kt)("img",{parentName:"p",src:"https://miro.medium.com/max/1400/1*dhyCWSbzpIi5iagR4OB4zQ.png",alt:null})),(0,a.kt)("p",null,"On top of this, Nx introduces one more non-standard, maybe even controversial, technique: There might be only ONE package.json at the root folder of the entire Monorepo. By default, when creating components using Nx, they will not have their own package.json! Instead, all will share the root package.json.  Going this way, all the Microservice/libraries share their dependencies and the installation time is improved.  Note: It\u2019s possible to create \u2018publishable\u2019 components that do have a package.json, it\u2019s just not the default."),(0,a.kt)("p",null,"I\u2019m concerned here. Sharing dependencies among packages increases the coupling, what if Microservice1 wishes to bump dependency1 version but Microservice2 can\u2019t do this at the moment? Also, package.json is part of Node.js  ",(0,a.kt)("em",{parentName:"p"},"runtime")," and excluding it from the component root loses important features like package.json main field or ESM exports (telling the clients which files are exposed). I ran some POC with Nx last week and found myself blocked \u2014 library B was wadded, I tried to import it from Library A but couldn\u2019t get the \u2018import\u2019 statement to specify the right package name. The natural action was to open B\u2019s package.json and check the name, but there is no Package.json\u2026 How do I determine its name? Nx docs are great, finally, I found the answer, but I had to spend time learning a new \u2018framework\u2019."),(0,a.kt)("h1",{id:"stop-for-a-second-its-all-about-your-workflow"},"Stop for a second: It\u2019s all about your workflow"),(0,a.kt)("p",null,"We deal with tooling and features, but it\u2019s actually meaningless evaluating these options before determining whether your preferred workflow is  ",(0,a.kt)("em",{parentName:"p"},"synchronized or independent")," (we will discuss this in a few seconds)",(0,a.kt)("em",{parentName:"p"},".")," This upfront  ",(0,a.kt)("em",{parentName:"p"},"fundamental"),"  decision will change almost everything."),(0,a.kt)("p",null,"Consider the following example with 3 components: Library 1 is introducing some major and breaking changes, Microservice1 and Microservice2 depend upon Library1 and should react to those breaking changes. How?"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Option A \u2014 The synchronized workflow-")," Going with this development style, all the three components will be developed and deployed in one chunk  ",(0,a.kt)("em",{parentName:"p"},"together"),". Practically, a developer will code the changes in Library1, test libray1 and also run wide integration/e2e tests that include Microservice1 and Microservice2. When they're ready, the version of all components will get bumped. Finally, they will get deployed  ",(0,a.kt)("em",{parentName:"p"},"together.")),(0,a.kt)("p",null,"Going with this approach, the developer has the chance of seeing the full flow from the client's perspective (Microservice1 and 2), the tests cover not only the library but also through the eyes of the clients who actually use it. On the flip side, it mandates updating all the depend-upon components (could be dozens), doing so increases the risk\u2019s blast radius as more units are affected and should be considered before deployment. Also, working on a large unit of work demands building and testing more things which will slow the build."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Option B \u2014 Independent workflow-")," This style is about working a unit by unit, one bite at a time, and deploy each component independently based on its personal business considerations and priority. This is how it goes: A developer makes the changes in Library1, they must be tested carefully in the scope of Library1. Once she is ready, the SemVer is bumped to a new major and the library is published to a package manager registry (e.g., npm). What about the client Microservices? Well, the team of Microservice2 is super-busy now with other priorities, and skip this update for now (the same thing as we all delay many of our npm updates,). However, Microservice1 is very much interested in this change \u2014 The team has to pro-actively update this dependency and grab the latest changes, run the tests and when they are ready, today or next week \u2014 deploy it."),(0,a.kt)("p",null,"Going with the independent workflow, the library author can move much faster because she does not need to take into account 2 or 30 other components \u2014 some are coded by different teams. This workflow also  ",(0,a.kt)("em",{parentName:"p"},"forces her"),"  to write efficient tests against the library \u2014 it\u2019s her only safety net and is likely to end with autonomous components that have low coupling to others. On the other hand, testing in isolation without the client\u2019s perspective loses some dimension of realism. Also, if a single developer has to update 5 units \u2014 publishing each individually to the registry and then updating within all the dependencies can be a little tedious."),(0,a.kt)("p",null,(0,a.kt)("img",{parentName:"p",src:"https://miro.medium.com/max/1400/1*eeJFL3_vo5tCrWvVY-surg.png",alt:null})),(0,a.kt)("p",null,"Synchronized and independent workflows illustrated"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"On the illusion of synchronicity")),(0,a.kt)("p",null,"In distributed systems, it\u2019s not feasible to achieve 100% synchronicity \u2014 believing otherwise can lead to design faults. Consider a breaking change in Microservice1, now its client Microservice2 is adapting and ready for the change. These two Microservices are deployed together but due to the nature of Microservices and distributed runtime (e.g., Kubernetes) the deployment of Microservice1 only fail. Now, Microservice2\u2019s code is not aligned with Microservice1 production and we are faced with a production bug. This line of failures can be handled to an extent also with a synchronized workflow \u2014 The deployment should orchestrate the rollout of each unit so each one is deployed at a time. Although this approach is doable, it increased the chances of large-scoped rollback and increases deployment fear."),(0,a.kt)("p",null,"This fundamental decision, synchronized or independent, will determine so many things \u2014 Whether performance is an issue or not at all (when working on a single unit), hoisting dependencies or leaving a dedicated node_modules in every package\u2019s folder, and whether to create a local link between packages which is described in the next paragraph."),(0,a.kt)("h1",{id:"layer-4-link-your-packages-for-immediate-feedback"},"Layer 4: Link your packages for immediate feedback"),(0,a.kt)("p",null,"When having a Monorepo, there is always the unavoidable dilemma of how to link between the components:"),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Option 1: Using npm \u2014")," Each library is a standard npm package and its client installs it via the standards npm commands. Given Microservice1 and Library1, this will end with two copies of Library1: the one inside Microservices1/NODE_MODULES (i.e., the local copy of the consuming Microservice), and the 2nd is the development folder where the team is coding Library1."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Option2: Just a plain folder \u2014")," With this, Library1 is nothing but a logical module inside a folder that Microservice1,2,3 just locally imports. NPM is not involved here, it\u2019s just code in a dedicated folder. This is for example how Nest.js modules are represented."),(0,a.kt)("p",null,"With option 1, teams benefit from all the great merits of a package manager \u2014 SemVer(!), tooling, standards, etc. However, should one update Library1, the changes won\u2019t get reflected in Microservice1 since it is grabbing its copy from the npm registry and the changes were not published yet. This is a fundamental pain with Monorepo and package managers \u2014 one can\u2019t just code over multiple packages and test/run the changes."),(0,a.kt)("p",null,"With option 2, teams lose all the benefits of a package manager: Every change is propagated immediately to all of the consumers."),(0,a.kt)("p",null,"How do we bring the good from both worlds (presumably)? Using linking. Lerna, Nx, the various package manager workspaces (Yarn, npm, etc) allow using npm libraries and at the same time link between the clients (e.g., Microservice1) and the library. Under the hood, they created a symbolic link. In development mode, changes are propagated immediately, in deployment time \u2014 the copy is grabbed from the registry."),(0,a.kt)("p",null,(0,a.kt)("img",{parentName:"p",src:"https://miro.medium.com/max/1400/1*9PkNrnbnibFdbvPieq-y9g.png",alt:null})),(0,a.kt)("p",null,"Linking packages in a Monorepo"),(0,a.kt)("p",null,"If you\u2019re doing the synchronized workflow, you\u2019re all set. Only now any risky change that is introduced by Library3, must be handled NOW by the 10 Microservices that consume it."),(0,a.kt)("p",null,"If favoring the independent workflow, this is of course a big concern. Some may call this direct linking style a \u2018monolith monorepo\u2019, or maybe a \u2018monolitho\u2019. However, when not linking, it\u2019s harder to debug a small issue between the Microservice and the npm library. What I typically do is  ",(0,a.kt)("em",{parentName:"p"},"temporarily link")," (with npm link) between the packages",(0,a.kt)("em",{parentName:"p"},","),"  debug, code, then finally remove the link."),(0,a.kt)("p",null,"Nx is taking a slightly more disruptive approach \u2014 it is using  ",(0,a.kt)("a",{parentName:"p",href:"https://www.typescriptlang.org/tsconfig#paths"},"TypeScript paths"),"  to bind between the components. When Microservice1 is importing Library1, to avoid the full local path, it creates a TypeScript mapping between the library name and the full path. But wait a minute, there is no TypeScript in production so how could it work? Well, in serving/bundling time it webpacks and stitches the components together. Not a very standard way of doing Node.js work."),(0,a.kt)("h1",{id:"closing-what-should-you-use"},"Closing: What should you use?"),(0,a.kt)("p",null,"It\u2019s all about your workflow and architecture \u2014 a huge unseen cross-road stands in front of the Monorepo tooling decision."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Scenario A \u2014")," If your architecture dictates a  ",(0,a.kt)("em",{parentName:"p"},"synchronized workflow"),"  where all packages are deployed together, or at least developed in collaboration \u2014 then there is a strong need for a rich tool to manage this coupling and boost the performance. In this case, Nx might be a great choice."),(0,a.kt)("p",null,"For example, if your Microservice must keep the same versioning, or if the team really small and the same people are updating all the components, or if your modularization is not based on package manager but rather on framework-own modules (e.g., Nest.js), if you\u2019re doing frontend where the components inherently are published together, or if your testing strategy relies on E2E mostly \u2014 for all of these cases and others, Nx is a tool that was built to enhance the experience of coding many  ",(0,a.kt)("em",{parentName:"p"},"relatively")," coupled components together. It is a great a sugar coat over systems that are unavoidably big and linked."),(0,a.kt)("p",null,"If your system is not inherently big or meant to synchronize packages deployment, fancy Monorepo features might increase the coupling between components. The Monorepo pyramid above draws a line between basic features that provide value without coupling components while other layers come with an architectural price to consider. Sometimes climbing up toward the tip is worth the consequences, just make this decision consciously."),(0,a.kt)("p",null,(0,a.kt)("img",{parentName:"p",src:"https://miro.medium.com/max/1400/1*c2qYYpVGG667bkum-gB-5Q.png",alt:null})),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"Scenario B\u2014")," If you\u2019re into an  ",(0,a.kt)("em",{parentName:"p"},"independent workflow")," where each package is developed, tested, and deployed (almost) independently \u2014 then inherently there is no need to fancy tools to orchestrate hundreds of packages. Most of the time there is just one package in focus. This calls for picking a leaner and simpler tool \u2014 Turborepo. By going this route, Monorepo is not something that affects your architecture, but rather a scoped tool for faster build execution. One specific tool that encourages an independent workflow is  ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/giltayar/bilt"},"Bilt"),"  by Gil Tayar, it\u2019s yet to gain enough popularity but it might rise soon and is a great source to learn more about this philosophy of work."),(0,a.kt)("p",null,(0,a.kt)("strong",{parentName:"p"},"In any scenario, consider workspaces \u2014")," If you face performance issues that are caused by package installation, then the various workspace tools Yarn/npm/PNPM, can greatly minimize this overhead with a low footprint. That said, if you\u2019re working in an autonomous workflow, smaller are the chances of facing such issues. Don\u2019t just use tools unless there is a pain."),(0,a.kt)("p",null,"We tried to show the beauty of each and where it shines. If we\u2019re allowed to end this article with an opinionated choice: We greatly believe in an independent and autonomous workflow where the occasional developer of a package can code and deploy fearlessly without messing with dozens of other foreign packages. For this reason, Turborepo will be our favorite tool for the next season. We promise to tell you how it goes."),(0,a.kt)("h1",{id:"bonus-comparison-table"},"Bonus: Comparison table"),(0,a.kt)("p",null,"See below a detailed comparison table of the various tools and features:"),(0,a.kt)("p",null,(0,a.kt)("img",{parentName:"p",src:"https://miro.medium.com/max/1400/1*iHX_IdPW8XXXiZTyjFo6bw.png",alt:null})),(0,a.kt)("p",null,"Preview only, the complete table can be  ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/practicajs/practica/blob/main/docs/docs/decisions/monorepo.md"},"found here")))}p.isMDXComponent=!0},1377:(e,t,o)=>{o.d(t,{Z:()=>n});const n=o.p+"assets/images/monorepo-high-level-291b29cc962144a43d78143889ba5d3b.png"}}]);